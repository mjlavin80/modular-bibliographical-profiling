{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c398d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, ast\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utilities import text_functions as tf\n",
    "from utilities import scikit_functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2793f73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>single_focus</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_review</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cluster</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brief</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_pdf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_type      \n",
       "                count\n",
       "5  single_focus  1093\n",
       "2         multi   487\n",
       "4    not_review   247\n",
       "1       cluster   244\n",
       "0         brief    82\n",
       "3        no_pdf     2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_csv('meta.csv', index_col=0)\n",
    "type_summary = df_meta.groupby('review_type').agg({'review_type':['count',]}).reset_index(drop=False).sort_values(by=('review_type', 'count'), ascending=False)\n",
    "type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4039f575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">genre_parsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonfiction</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiction</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poetry</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drama</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre_parsed      \n",
       "               count\n",
       "2   nonfiction   801\n",
       "1      fiction   226\n",
       "3       poetry    34\n",
       "0        drama    18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single = pd.read_csv('single_author_meta.csv', index_col=0)\n",
    "df_single_genre_summary = df_single.groupby('genre_parsed').agg({'genre_parsed':['count',]}).reset_index(drop=False).sort_values(by=('genre_parsed', 'count'), ascending=False)\n",
    "df_single_genre_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c83c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ngrams data ... this will probably take about 30-60 seconds wall time\n",
    "\n",
    "ngram_stores_lower = {}\n",
    "\n",
    "base = 'extracted_features/ngrams'\n",
    "    \n",
    "for e in range(0,5):\n",
    "    ngram_store = {}\n",
    "    for i in df_single['record_id']:\n",
    "        this_csv= f'{base}/{str(e)}/{str(i)}.csv'\n",
    "        df = pd.read_csv(this_csv, index_col=0).dropna().reset_index(drop=True).set_index('ngram')\n",
    "        mydict = df['count'].to_dict()\n",
    "        try:\n",
    "            mycounter = Counter({ast.literal_eval(k):v for k,v in mydict.items()})\n",
    "        except:\n",
    "            mycounter = Counter(mydict)\n",
    "        ngram_store[i] = mycounter\n",
    "    ngram_stores_lower[e] = ngram_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f55f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review text list of counters \n",
    "review_counters_all = [ngram_stores_lower[0][i] for i in df_single['record_id']]\n",
    "review_counters_all_no_stops = tf.remove_from_list_of_dicts(stopwords.words('english')+['nan'], review_counters_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce8e869f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>match_string_raw</th>\n",
       "      <th>match_column</th>\n",
       "      <th>no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124900101</td>\n",
       "      <td>Lucien Carr</td>\n",
       "      <td>[lucien, carr]</td>\n",
       "      <td>[lucien, carr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89760874</td>\n",
       "      <td>W. S. Jeans</td>\n",
       "      <td>[w, s, jeans]</td>\n",
       "      <td>[w, jeans]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89659668</td>\n",
       "      <td>Lord Byron</td>\n",
       "      <td>[lord, byron]</td>\n",
       "      <td>[lord, byron]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89659668</td>\n",
       "      <td>W. A. Lewis Bettany</td>\n",
       "      <td>[w, a, lewis, bettany]</td>\n",
       "      <td>[w, lewis, bettany]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124736362</td>\n",
       "      <td>Compton Mackenzie</td>\n",
       "      <td>[compton, mackenzie]</td>\n",
       "      <td>[compton, mackenzie]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id      match_string_raw            match_column  \\\n",
       "0  124900101           Lucien Carr          [lucien, carr]   \n",
       "1   89760874           W. S. Jeans           [w, s, jeans]   \n",
       "2   89659668            Lord Byron           [lord, byron]   \n",
       "3   89659668   W. A. Lewis Bettany  [w, a, lewis, bettany]   \n",
       "4  124736362     Compton Mackenzie    [compton, mackenzie]   \n",
       "\n",
       "               no_stops  \n",
       "0        [lucien, carr]  \n",
       "1            [w, jeans]  \n",
       "2         [lord, byron]  \n",
       "3   [w, lewis, bettany]  \n",
       "4  [compton, mackenzie]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata text list of counters\n",
    "df_authors = pd.read_csv('authors_meta.csv', index_col=0)\n",
    "df_titles = pd.read_csv('titles_meta.csv', index_col=0)\n",
    "df_publishers = pd.read_csv('publishers_meta.csv', index_col=0)\n",
    "\n",
    "df_authors = df_authors.rename(mapper={'reviewed_author_name':'match_string_raw'}, axis=1)\n",
    "df_titles = df_titles.rename(mapper={'reviewed_book_title':'match_string_raw'}, axis=1)\n",
    "df_publishers = df_publishers.rename(mapper={'reviewed_book_publisher':'match_string_raw'}, axis=1)\n",
    "\n",
    "def make_columns(df):\n",
    "    df['match_string_raw'] = df['match_string_raw'].fillna('')\n",
    "    df['match_column'] = [tf.preprocess_text(str(i).lower()) for i in df['match_string_raw']]\n",
    "    df['no_stops'] = [[d for d in i if d not in stopwords.words('english')] for i in df['match_column']]\n",
    "    return df\n",
    "\n",
    "df_authors = make_columns(df_authors)\n",
    "df_titles = make_columns(df_titles)\n",
    "df_publishers = make_columns(df_publishers)\n",
    "df_authors.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f8a88",
   "metadata": {},
   "source": [
    "## Naive BOW Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ff29da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_counters_store = {}\n",
    "\n",
    "for df in [df_authors, df_titles, df_publishers]:\n",
    "    \n",
    "    for e, row in df.iterrows():\n",
    "        data = row['no_stops'].copy()\n",
    "        try:\n",
    "            meta_counters_store[row['record_id']].extend([i for i in data if i !='nan'])\n",
    "        except KeyError:\n",
    "            meta_counters_store[row['record_id']] = [i for i in data if i !='nan']\n",
    "\n",
    "meta_counters_all = [Counter(meta_counters_store[i]) for i in df_single['record_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c5a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_meta_combined = review_counters_all_no_stops + meta_counters_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6f5e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(review_meta_combined)\n",
    "X_reviews_only = v.transform(review_counters_all_no_stops)\n",
    "X_meta_only = v.transform(meta_counters_all)\n",
    "\n",
    "# to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85207a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 52s, sys: 14.4 s, total: 4min 7s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_meta_records = sf.pairwise_cosine(X_reviews_only, X_meta_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "750024e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 4.89 s, total: 22.8 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_meta_scores = sf.pairwise_performance(reviews_meta_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21483ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 0.8619091751621872], 791)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_meta_scores[0], len(reviews_meta_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f85f4",
   "metadata": {},
   "source": [
    "## Pretrained NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ents_joined = pd.read_csv('extracted_features/spacy_entities_all.csv', index_col=0)\n",
    "df_ents_joined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ner_counters_store = {}\n",
    "entities = ['PERSON', 'GPE', 'NORP', 'ORG', 'FAC', 'EVENT', 'LOC', 'PRODUCT', 'WORK_OF_ART', 'LAW']        \n",
    "df_ents_selected = df_ents_joined.loc[df_ents_joined['label'].isin(entities)]\n",
    "df_ents_selected['match_column'] = [tf.preprocess_text(str(i).lower()) for i in df_ents_selected['text']]\n",
    "df_ents_selected['no_stops'] = [[d for d in i if d not in stopwords.words('english')] for i in df_ents_selected['match_column']]\n",
    "df_ents_selected.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, row in df_ents_selected.iterrows():\n",
    "    data = row['no_stops'].copy()\n",
    "    try:\n",
    "        spacy_ner_counters_store[row['record_id']].extend(data)\n",
    "    except KeyError:\n",
    "        spacy_ner_counters_store[row['record_id']] = data\n",
    "            \n",
    "spacy_ner_counters_all = [Counter(spacy_ner_counters_store[i]) for i in df_single['record_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_meta_combined = spacy_ner_counters_all + meta_counters_all\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(spacy_meta_combined)\n",
    "X_spacy_ner_only = v.transform(spacy_ner_counters_all)\n",
    "X_meta_only = v.transform(meta_counters_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b69a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_meta_records = sf.pairwise_cosine(X_spacy_ner_only, X_meta_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_meta_scores = sf.pairwise_performance(spacy_meta_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261289e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_meta_scores[0], len(spacy_meta_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68b46d",
   "metadata": {},
   "source": [
    "## Rule-Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features based on all matching title ngrams, publisher ngrams, author surnames and associated names \n",
    "x1 = list(df_publishers['no_stops'])\n",
    "pub_tokens = list(set([j for i in x1 for j in i]))\n",
    "\n",
    "x2 = list(df_titles['no_stops'])\n",
    "title_tokens = list(set([j for i in x2 for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load extracted author data\n",
    "df_ac = pd.read_csv('extracted_features/author_candidates.csv', index_col=0)\n",
    "df_an = pd.read_csv('extracted_features/associated_names.csv', index_col=0)\n",
    "\n",
    "# remove nan, lowercase all, reduce to unique \n",
    "x3 = [eval(i) for i in df_ac.loc[df_ac['entity'] != 'nan']['entity']] \n",
    "x4 = [eval(i) for i in df_an.loc[df_an['entity'] != 'nan']['entity']]  \n",
    "\n",
    "candidate_tokens = list(set([j.lower() for i in x3 for j in i]))\n",
    "associated_tokens = list(set([j.lower() for i in x4 for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_feature_tokens = [i for i in list(set(candidate_tokens + associated_tokens + pub_tokens + title_tokens)) if i != 'nan']\n",
    "len(pub_tokens), len(title_tokens), len(candidate_tokens), len(associated_tokens), len(extracted_feature_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_counters_extracted_features = tf.cull_list_of_dicts(extracted_feature_tokens, review_counters_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_meta_combined = review_counters_extracted_features + meta_counters_all\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(extracted_meta_combined)\n",
    "X_extracted_only = v.transform(review_counters_extracted_features)\n",
    "X_meta_only = v.transform(meta_counters_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_meta_records = sf.pairwise_cosine(X_extracted_only, X_meta_only)\n",
    "extracted_meta_scores = sf.pairwise_performance(extracted_meta_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_bow = pd.DataFrame.from_records(reviews_meta_scores, columns = ['window', 'recall']).set_index('window')\n",
    "df_scores_rules = pd.DataFrame.from_records(extracted_meta_scores, columns = ['window', 'recall']).set_index('window')\n",
    "df_scores_ner = pd.DataFrame.from_records(spacy_meta_scores, columns = ['window', 'recall_ner']).set_index('window')\n",
    "\n",
    "df_scores_all = df_scores_bow.join(df_scores_rules, lsuffix='_bow', rsuffix='_rules').join(df_scores_ner).reset_index()\n",
    "df_scores_all = df_scores_all.loc[df_scores_all['window'] % 5 == 0]\n",
    "df_scores_all = df_scores_all.head(10)\n",
    "\n",
    "\n",
    "dfm = df_scores_all.rename(mapper={'recall_bow':'Naive BOW', 'recall_ner':'Pretrained NER', 'recall_rules':'Rule-based', }, axis=1).melt('window', var_name='column', value_name='score')\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(9, 7))\n",
    "sns.lineplot(x='window', y='score', hue='column', data=dfm, marker='o', markerfacecolor='black').set(title='Predicted Label is Correct or Close', ylabel='Percent of Reviews Correct or Close', xlabel='Proximity Threshold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ad0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_meta_scores[789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5339af",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_meta_scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e90be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def prf(records):\n",
    "    df = pairwise_df(records)\n",
    "    return precision_score(df['source'], df['target'], average='weighted', zero_division=0.0), recall_score(df['source'], df['target'], average='weighted'), f1_score(df['source'], df['target'], average='weighted')\n",
    "\n",
    "prf(reviews_meta_records), prf(extracted_meta_records), prf(spacy_meta_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2fb4c",
   "metadata": {},
   "source": [
    "## False Positives Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f7846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_fp(df):\n",
    "    df_fp = df.loc[df['source'] != df['target']]\n",
    "    fp_counts = df_fp.groupby('target').count()[['score']].sort_values(by='score', ascending=False)\n",
    "    return fp_counts\n",
    "\n",
    "def tp_vs_fp_scores(df, index):\n",
    "    return df.loc[df['target'] == index].sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_df = pairwise_df(reviews_meta_records)\n",
    "naive_fp = analyze_fp(naive_df)\n",
    "\n",
    "spacy_df = pairwise_df(spacy_meta_records)\n",
    "spacy_fp = analyze_fp(spacy_df)\n",
    "\n",
    "extracted_df = pairwise_df(extracted_meta_records)\n",
    "extracted_fp = analyze_fp(extracted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_joined = naive_fp.join(spacy_fp, how='outer', lsuffix='_naive', rsuffix='_spacy').join(extracted_fp, how='outer').fillna(0).rename(mapper={'score':'extracted_score'}, axis=1)\n",
    "fps_joined['sum'] = fps_joined.sum(axis=1)\n",
    "fps_joined['mean_naive_extracted'] = (fps_joined['score_naive'] + fps_joined['extracted_score'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_joined.sort_values(by='score_spacy', ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_joined.sort_values(by='mean_naive_extracted', ascending=False).head(15).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e248d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_spacy = fps_joined.sort_values(by='score_spacy', ascending=False).head(3).index.to_list()\n",
    "worst_overall = fps_joined.sort_values(by='sum', ascending=False).head(15).index.to_list()\n",
    "worst_naive_extracted = fps_joined.sort_values(by='mean_naive_extracted', ascending=False).head(15).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fps_joined[['score_naive','score_spacy','extracted_score']].corr().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ab385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_meta(fp_index):\n",
    "    ri = df_single.reset_index().iloc[fp_index]['record_id']\n",
    "    a = ' '.join(df_authors.loc[df_authors['record_id'] == ri]['match_string_raw'].to_list())\n",
    "    t = ' '.join(df_titles.loc[df_titles['record_id'] == ri]['match_string_raw'].to_list())\n",
    "    p = ' '.join(df_publishers.loc[df_publishers['record_id'] == ri]['match_string_raw'].to_list())\n",
    "    return [a,t,p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa506697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in worst_spacy:\n",
    "    print(index_to_meta(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13628430",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in worst_spacy:\n",
    "    print(meta_counters_all[i].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in worst_naive_extracted :\n",
    "    print(index_to_meta(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in worst_naive_extracted:\n",
    "    print(meta_counters_all[i].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce823e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in worst_spacy:\n",
    "    print(list(spacy_ner_counters_all[i].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738075b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_vs_fp_scores(naive_df, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796accf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_vs_fp_scores(naive_df, 707)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_tp_fp(df, strategy):\n",
    "    # naive TPs\n",
    "    tp = pd.DataFrame(df.loc[df['source'] == df['target']]['score'].describe())\n",
    "    fp = pd.DataFrame(df.loc[df['source'] != df['target']]['score'].describe())\n",
    "    joined = tp.join(fp, lsuffix='_tp', rsuffix='_fp')\n",
    "    return joined.rename(mapper={'score_tp':f'{strategy}_tp', 'score_fp':f'{strategy}_fp', }, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_d = describe_tp_fp(naive_df, 'naive')\n",
    "spacy_d = describe_tp_fp(spacy_df, 'ner')\n",
    "extracted_d = describe_tp_fp(extracted_df, 'rule_based')\n",
    "\n",
    "joined_d = naive_d.join(spacy_d).join(extracted_d)\n",
    "print(joined_d[joined_d.index.isin(['mean', '25%','50%','75%','min', 'max'])].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logit_on_cos_sim(df):\n",
    "    X = df.loc[df['source'] != df['target']]['score'].to_list() +  df.loc[df['source'] == df['target']]['score'].to_list()\n",
    "    X_array = np.array(X).reshape(-1, 1)\n",
    "    y = [ 1 for i in df.loc[df['source'] != df['target']]['score'].to_list()] + [0 for i in df.loc[df['source'] == df['target']]['score'].to_list()]\n",
    "    clf = LogisticRegression(class_weight={0: 0.2, 1:0.8}).fit(X_array, y)\n",
    "    predicted = clf.predict(X_array)\n",
    "    probs = clf.predict_proba(X_array)\n",
    "    #return clf.score(X_array, y)\n",
    "    df_logit = pd.DataFrame()\n",
    "    df_logit['score'] = X\n",
    "    df_logit['predicted'] = predicted\n",
    "    df_logit['actual'] = y\n",
    "    df_logit['prob_correct'] = [i[0] for i in probs]\n",
    "    df_logit['prob_incorrect'] = [i[1] for i in probs]\n",
    "    df_logit['correctly_classified'] = df_logit['predicted'] == df_logit['actual']\n",
    "    df_logit_sorted = df_logit.sort_values(by='score')\n",
    "    return df_logit_sorted\n",
    "\n",
    "def model_acc(df):\n",
    "    return df.loc[df['predicted'] == df['actual']].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3527d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit_naive = logit_on_cos_sim(naive_df)\n",
    "model_acc(df_logit_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit_spacy = logit_on_cos_sim(spacy_df)\n",
    "model_acc(df_logit_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c770e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit_extracted = logit_on_cos_sim(extracted_df)\n",
    "model_acc(df_logit_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25222dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile_accuracy(df, q=5):\n",
    "    r = math.ceil(df.shape[0]/q)\n",
    "    df_low = df.head(r)\n",
    "    df_high = df.tail(r*(q-1))\n",
    "    output = []\n",
    "    for i in [df_low, df_high]:\n",
    "        this_df = i.groupby(['predicted', 'actual']).count()[['score']].rename(mapper={'score':'count'}, axis=1)\n",
    "        output.append(this_df)\n",
    "        this_df['min_cos_sim'] = i['score'].min()\n",
    "        this_df['max_cos_sim'] = i['score'].max()\n",
    "    return output[0].join(output[1], how='outer', lsuffix='_low', rsuffix='_high')\n",
    "\n",
    "get_quantile_accuracy(df_logit_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577872de",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_naive = get_quantile_accuracy(df_logit_naive)\n",
    "quantiles_extracted = get_quantile_accuracy(df_logit_extracted)\n",
    "quantiles_spacy = get_quantile_accuracy(df_logit_spacy)\n",
    "\n",
    "m = {}\n",
    "for i in quantiles_spacy.columns:\n",
    "    m[i] = i + '_spacy'    \n",
    "    \n",
    "quantiles_spacy = quantiles_spacy.rename(mapper=m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e794ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_joined = quantiles_naive.join(quantiles_extracted, lsuffix='_naive', rsuffix='_extracted').join(quantiles_spacy).fillna(0).reset_index()\n",
    "\n",
    "for i in ['naive', 'extracted', 'spacy']:\n",
    "    quantiles_joined['sum_'+i] = quantiles_joined[f'count_low_{i}'] + quantiles_joined[f'count_high_{i}']\n",
    "\n",
    "quantiles_joined\n",
    "\n",
    "quantiles_separated = []\n",
    "for x in ['naive', 'extracted', 'spacy']:\n",
    "    quantiles_separated.append(quantiles_joined[['predicted', 'actual'] + [i for i in quantiles_joined.columns if x in i]])\n",
    "quantiles_separated[2][[i for i in quantiles_separated[2].columns if 'cos_sim' in i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0817709",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in quantiles_separated:\n",
    "    #x_selected = x[[i for i in x.columns if 'count' in i]]\n",
    "    correct = x.loc[x['predicted'] == x['actual']].set_index('actual')\n",
    "    accuracies = []\n",
    "    for y in ['count_low', 'count_high']:\n",
    "        c = [i for i in x.columns if y in i]\n",
    "        acc = correct.sum()[c[0]] / x.sum()[c[0]]\n",
    "        print(y, acc)\n",
    "        accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.ceil(1079/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f98add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit_naive.tail(500).groupby(['actual']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_r_plot(df, strategy):\n",
    "    mpl.rcParams['lines.markersize'] = 4 \n",
    "    fig = plt.subplots(figsize=(9, 7))\n",
    "    precision, recall, thresholds = precision_recall_curve(df['actual'],df['prob_correct'], pos_label=0)\n",
    "    df_pr_curve = pd.DataFrame()\n",
    "    df_pr_curve['precision'] = precision\n",
    "    df_pr_curve['recall'] = recall\n",
    "    df_pr_curve['thresholds'] = np.insert(thresholds, 0, 0)\n",
    "    sns.lineplot(x='recall', y='precision', data=df_pr_curve, marker='o', markerfacecolor='black').set(title=f'Precision-Recall Curve ({strategy} Model)', ylabel='Precision', xlabel='Recall')\n",
    "    return df_pr_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_curve = p_r_plot(df_logit_naive, \"Naive BOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_curve = p_r_plot(df_logit_spacy, \"Pre-trained NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_curve = p_r_plot(df_logit_extracted, \"Rule-Based\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
